# SRIE-Net: Semantic-aware Relation and Identity Enhancement Network for Cloth-Changing Person Re-Identifications
##  News

## üß© Overview

This repository implements **SRIE-Net** for **cloth-changing person re-identification (CC-ReID)**.
Experiments are mainly conducted on three datasets: **PRCC**, **LTCC**, and **NKUP**.

---

## Dataset Layout

The project uses three datasets: **LTCC**, **PRCC**, and **NKUP**. We recommend placing them under a common root directory, for example:

```text
data/
‚îú‚îÄ‚îÄ ltcc
‚îú‚îÄ‚îÄ prcc
‚îî‚îÄ‚îÄ nkup
```

Here, `<DATA_ROOT>` is specified by `DATASETS.ROOT_DIR` in the config files, and each sub-folder name (e.g., `ltcc`, `prcc`, `nkup`) is used in `DATASETS.NAMES`.

The `mask_18` folder contains the segmentation masks generated by the SCHP module:
- **Training phase**: if you enable the mask branch (default setting in the paper), you must ensure that each dataset root (`ltcc/`, `prcc/`, `nkup/`, etc.) contains a corresponding `mask_18` folder whose structure is aligned with the original images.
- **Test-only / inference phase**: if you only want to evaluate a trained model without using the mask branch, you can omit `mask_18` and organize the images as a standard Re-ID dataset.

### 1. LTCC directory structure

```text
ltcc
‚îú‚îÄ‚îÄ mask_18 (SCHP outputs)
‚îÇ   ‚îî‚îÄ‚îÄ train
‚îú‚îÄ‚îÄ query
‚îú‚îÄ‚îÄ test
‚îî‚îÄ‚îÄ train

```

- `train`: all training images.
- `test`: all testing images (used for evaluation).
- `query`: query images (used for retrieval).
- `mask_18`: SCHP segmentation results for LTCC, with a directory structure aligned to the original images.
   - **Training**: required if you use the mask branch; keep this folder under the `ltcc` root.
   - **Test only**: can be omitted if you do not use mask features.

In the configs, you typically set:

- `DATASETS.ROOT_DIR: <DATA_ROOT>`
- `DATASETS.NAMES: ('ltcc')`

---

### 2. PRCC directory structure

```text
prcc
‚îú‚îÄ‚îÄ rgb
‚îÇ   ‚îú‚îÄ‚îÄ train
‚îÇ   ‚îú‚îÄ‚îÄ test
‚îÇ   ‚îî‚îÄ‚îÄ val
‚îî‚îÄ‚îÄ mask_18 (SCHP outputs)
```

- `rgb/*`: RGB images split into `train / test / val`.
- `sketch/*`: sketch images, also split into `train / test / val` (if used).
- `mask_18`: SCHP masks corresponding to PRCC images, aligned with the `rgb` directory.
   - **Training**: required if you want to use mask information to boost performance; keep `mask_18` under the `prcc` root.
   - **Test only**: can be omitted when not using the mask branch.

In the configs, you typically set:

- `DATASETS.ROOT_DIR: <DATA_ROOT>`
- `DATASETS.NAMES: ('prcc',)`

---

### 3. NKUP directory structure

```text
nkup
‚îú‚îÄ‚îÄ mask_18 (SCHP outputs)
‚îÇ   ‚îî‚îÄ‚îÄ bounding_box_train
‚îú‚îÄ‚îÄ bounding_box_train
‚îú‚îÄ‚îÄ bounding_box_test
‚îî‚îÄ‚îÄ query
```

- `bounding_box_train`: training images.
- `bounding_box_test`: testing images.
- `query`: query images.
- `mask_18`: SCHP masks for NKUP images.
   - **Training**: if you enable mask-related modules, place `mask_18` under the `nkup` root and align it with the above sub-folders.
   - **Test only**: can be omitted if you only run inference on existing checkpoints without using mask features.

In the configs, you typically set:

- `DATASETS.ROOT_DIR: <DATA_ROOT>`
- `DATASETS.NAMES: ('nkup',)`

---

## üìÇ Project Structure

1. **`config/`**  
   - Contains a single Python configuration file.

2. **`configs/`**  
   - Each sub-folder corresponds to one dataset (e.g., `LTCC/`, `Prcc/`, `NKUP/`, etc.).  
   - All datasets share a similar configuration structure; these files mainly define dataset-specific output paths and training hyper-parameters.  
   - There are many folders; **the most important ones for the paper are `LTCC/`, `Prcc/`, and `NKUP/`**.  
   - Each dataset has multiple `.yml` files, but in the paper **the used configuration is always `vit_transreid_stride_384.yml`**. All three datasets use this same config.

3. **`datasets/`**  
   - Contains all Python scripts for loading and preprocessing datasets corresponding to those under `configs/`.  

4. **`figs/`**  
   - Stores network architecture and framework diagrams.

5. **`grad_cam/`**  
   - Contains Grad-CAM-related configuration/script (only one key config/script is used).

6. **`logs/`**  
   - Stores outputs from each training/testing run, including:  
     - Evaluation tables, result images, etc.  
     - The config file used for that run.  
     - The best model weights for that run.  
   - **This folder is very important**: it is where you will find the best checkpoints when reproducing results. During testing you must point `TEST.WEIGHT` to the correct file in this folder.

7. **`loss/`**  
   - Contains different loss implementations, all written as classes for convenient reuse.

8. **`model/`**  
   - Contains all model definition scripts, including `__init__.py` and backbone implementations built with PyTorch.  
   - These are **model definition scripts only**, not the main training script.  
   - **The only place you must modify:**  
     - In `make_model.py` (around line 324), the path to the `pose_hrnet` pretrained weights.  
     - We have already set it to a relative path; **you only need to place `pose_hrnet_w32_256x192.pth` in the project root directory**.

9. **`processor/`**  
   - Contains the high-level training pipeline logic, orchestrating calls to different modules and importing components from other folders.  
   - There are two main script files here; one of them has detailed comments explaining:  
     - Which function is called at each step.  
     - What the input and output arguments are.  
     - The author's understanding and debugging hints when training results deviate significantly from normal.

10. **`solver/`**  
    - Contains all scripts related to optimization during training, including learning rate schedulers, optimizers, etc., all wrapped as classes.  
    - The main entry points are `make_optimizer.py` and `lr_scheduler.py`.

11. **`utils/`**  
    - Utility scripts used throughout training: file I/O, log generation, and re-ranking tools, etc.

---

## Environment & Data Preparation

1. **Create a virtual environment**  
   We provide both `environment.yml` and `requirements.txt`. You can choose either method according to your environment.

   - Using Conda:

     ```bash
     conda env create -f environment.yml
     conda activate py
     ```

   - Using pip:

     ```bash
     pip install -r requirements.txt
     ```

2. **Download datasets**  
   Because some datasets require official permission to access, we provide already pre-processed versions of the three datasets PRCC, LTCC, and NKUP to make reproduction easier. To respect and protect the original authors‚Äô copyrights, if you need to download the datasets, please obtain them through the official channels.

3. **Download pretrained weights**  
   Two pretrained weight files are used:

   - `pose_hrnet_w32_256x192.pth`  
   - `jx_vit_base_p16_224-80ecf9dd.pth`

   Download links:

   - `pose_hrnet_w32_256x192.pth`: [Baidu Disk](https://pan.baidu.com/s/1mhH35EuEZ9xj-q4hgobouw?pwd=3334) ¬∑ [Google Drive](https://drive.google.com/file/d/12pFIWmLaMMABT_qbyfAZpG96qR-9n5UK/view?usp=sharing)
   - `jx_vit_base_p16_224-80ecf9dd.pth`: [Baidu Disk](https://pan.baidu.com/s/1P2mzM6vTpBWxo_V5nLh5lg?pwd=3333) ¬∑ [Google Drive](https://drive.google.com/file/d/1AsSxOgN97r6TAkME76uEB1ry0DupVVIr/view?usp=sharing)

   **All pretrained weight files must be placed in the project root directory**, and referenced via `PRETRAIN_PATH` in each dataset's config.

---

## Configuration Files

For each dataset, you should modify the corresponding `.yml` config file, always using `vit_transreid_stride_384.yml`:

- PRCC: `./configs/Prcc/vit_transreid_stride_384.yml`  
- NKUP: `./configs/NKUP/vit_transreid_stride_384.yml`  
- LTCC: `./configs/LTCC/vit_transreid_stride_384.yml`

Important fields:

- `PRETRAIN_PATH`: path to the ViT pretrained weights (`jx_vit_base_p16_224-80ecf9dd.pth`).
- `SOLVER`: contains random seed, optimizer settings, `IMS_PER_BATCH` (batch size), etc. You can tune them according to your hardware.
- `OUTPUT_DIR`: output directory for logs and checkpoints (at the end of the config file). By default, it is under the project root `logs/` directory, but you can change it as you like.

---

## üèãÔ∏è Training

Besides setting the random seed inside the config files, you can also override seeds via command-line arguments to better demonstrate reproducibility.

- **PRCC dataset**

```bash
python train_xi.py --config_file ./configs/Prcc/vit_transreid_stride_384.yml MODEL.DEVICE_ID "('0')" SOLVER.SEED 123456 OUTPUT_DIR './logs/prcc/'
```

- **LTCC dataset**

```bash
python train_xi.py --config_file ./configs/LTCC/vit_transreid_stride_384.yml MODEL.DEVICE_ID "('0')" SOLVER.SEED 1234 OUTPUT_DIR './logs/ltcc/'
```

- **NKUP dataset**

```bash
python train_xi.py --config_file ./configs/NKUP/vit_transreid_stride_384.yml MODEL.DEVICE_ID "('0')" SOLVER.SEED 1234 OUTPUT_DIR './logs/nkup/'
```

Notes:
- `MODEL.DEVICE_ID` controls which GPU to use, e.g., single GPU `"('0')"`.
- `OUTPUT_DIR` can override the default path defined at the bottom of the `.yml` file.

---

## üîç Testing / Inference

The script `test.py` is used for model evaluation.

### Core Pipeline

1. Load config file via `--config_file`.  
2. Build the test data loader.  
3. Build the model architecture.  
4. Load trained weights via `model.load_param(cfg.TEST.WEIGHT)`.  
5. Run inference via `do_inference()`.  
6. Print evaluation results (mAP, Rank-1, Rank-5, Rank-10).

---

## ‚úÖ Recommended Testing Procedure

0. First, download the best trained weight files corresponding to the paper results:

   - PRCC: [Baidu Disk](https://pan.baidu.com/s/1v2Ibm-biTcs6j6-NY6nrnQ?pwd=1112) ¬∑ [Google Drive](https://drive.google.com/file/d/1N9k28J2VAIftTgbTYbLB1HwrwaZBdF3V/view?usp=sharing)
   - LTCC: [Baidu Disk](https://pan.baidu.com/s/1XHS5AsT5le_UmS-tR-3ntQ?pwd=1111) ¬∑ [Google Drive](https://drive.google.com/file/d/1ZtLzOtbAdqaHOnc_gFdrr9gjOPvrFZHd/view?usp=drive_link)
   - NKUP: [Baidu Disk](https://pan.baidu.com/s/1WkGYThtJd47hbyk3en5hJA?pwd=1113) ¬∑ [Google Drive](https://drive.google.com/file/d/1wznFuccnLvCTPbLkVJMkE8Zbg8l7PQWS/view?usp=sharing)

   Place these three files in any location you prefer, and specify that location in the `TEST.WEIGHT` parameter.

1. Optionally create a dedicated testing config by copying, e.g., `vit_transreid_stride_test.yml`.  
2. Set `MODEL.DEVICE_ID` for testing (usually a single GPU is enough).  
3. Edit `DATASETS` section:  
   - `NAMES`: the name of the dataset folder you use under the given root.  
   - `ROOT_DIR`: root directory containing all dataset folders.  
4. Edit `TEST` section:  
   - `WEIGHT: '../logs/xxx.pth'` (path to the best checkpoint you want to test).  
   - `IMS_PER_BATCH: xxx` (batch size for testing).  
5. Set `OUTPUT_DIR`: path where testing logs and results will be saved.  
6. Run `test.py` from the command line. Just like training, you can override config values via CLI arguments to make sure they take effect.

The authors have reserved their best pretrained models and training/testing logs in the project, and also provide a complete testing video to demonstrate result authenticity.

Key arguments:

- `--config_file`: path to the config file. If you want to store test results separately, you can modify the output path at the bottom of this config.  
- `TEST.WEIGET` (spelled as in the original code/comment): path to the weights used for testing. By default, it points to an existing best model. If you just trained a new model, you should change this path.  
- `OUTPUT_DIR`: if you prefer not to modify the config file, you can override the output directory directly via this argument; it will take precedence over the path in the config.

### Example Testing Commands

- **PRCC dataset**

```bash
python test.py --config_file ./configs/Prcc/vit_transreid_stride_384.yml MODEL.DEVICE_ID "('0')" TEST.WEIGHT './logs/prcc/123456/transformer_best.pth' OUTPUT_DIR './logs/prcc/123456/'
```

- **NKUP dataset**

```bash
python test.py --config_file ./configs/NKUP/vit_transreid_stride_384.yml MODEL.DEVICE_ID "('0')" TEST.WEIGHT './logs/nkup/transformer_best.pth' OUTPUT_DIR './logs/nkup/'
```

- **LTCC dataset**

```bash
python test.py --config_file ./configs/LTCC/vit_transreid_stride_384.yml MODEL.DEVICE_ID "('0')" TEST.WEIGHT './logs/ltcc/transformer_best.pth' OUTPUT_DIR './logs/ltcc/'
```




## üìÑ Citation
If you use our method or codes in your research, please cite:
```
@inproceedings{ma_srie_2025, 
  title={SRIE-Net: Semantic-aware Relation and Identity Enhancement Network for Cloth-Changing Person Re-Identifications},
  author={Ran Wang, Haixia Xu, Yibo Zhao, Chunjie Ma, Riwei Wang, Zan Gao},
  booktitle={},
  year={2025}
}
```
